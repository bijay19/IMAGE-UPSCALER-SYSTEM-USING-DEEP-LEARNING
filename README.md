The project builds a U-Net-based CNN for single-image super-resolution, trained on high-resolution datasets with a custom degradation pipeline. It uses SE blocks, pixel shuffle, and residual bottlenecks for detail recovery. Models are trained with MAE and perceptual loss (VGG19). Augmentation and mixed precision improve robustness and efficiency. Evaluated with PSNR, SSIM, and MAE, the system produces sharper, high-quality images without requiring GANs.
